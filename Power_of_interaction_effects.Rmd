---
title: 'Computing the power of interaction effects by simulation'
author: "Peter Verboon"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: html_document
---

```{r setup1, include=FALSE}
library(pander)
panderOptions('digits', 3)
panderOptions('round', 3)
panderOptions('keep.trailing.zeros', TRUE)
```

In this paper we provide a tool for planning a sample for a simple design. The reader who is planning his study and needs to know the optimal sample size for his study has two options. First, he may study the tables with recommended sample sizes given in this paper and select the table, which equals or is close to the design he actually intends to use.  Second, he may use the R-functions that we have developed to run a simulation with the parameters of his choice. These functions are freely available.
Here we focus on conditional versus unconditional effects of a predictor on a dependent variable. When the effect of a predictor is conditional of the value of another variable this is called moderation.


### The moderation model 

In a moderation model we assume that the effect of the predictor x on the dependent variable y is conditional on another variable z, which is called the moderator. In the statistical model (Hayes, 2013) this implies that there is an interaction term between x and z in the model (usually the product between both variables: xz). The basic moderation model thus consists of three predictors of y: x, z and xz. 
Assume the following simple moderation model:

$$y_i=b_0+b_1 x_i+b_2 z_i+ b_3 x_i z_i+ϵ_i, 	[1]$$  

with y the dependent variable measured on subject i, x the predictor and z the moderator, xz the interaction term. The b’s are regression coefficients. Variables x and z are distributed as N(0,1) and the error term ε as N(0, $σ_ε$). The correlation between x and z is r. The error term ε is uncorrelated with both x and z.

### Power analysis by using simulation
To simulate the model for a power analysis, we use R. We start by loading the necessary packages.
```{r packages-0, eval=FALSE, include=TRUE}
require('userfriendlyscience');
require(MASS)
require(lm.beta)
require(plyr)
```

```{r packages-1, eval=TRUE, include=FALSE}
require('userfriendlyscience');
require(MASS)
require(lm.beta)
require(plyr)
```

Now that the packages are installed and loaded, we can define the function used to run the simulation. 
The parameters that can be chosen are:   

```
1.    A number of different sample sizes
2.    Different random error levels
3.    Different correlations between the predictors
4.    The three unstandardized parameters of respectively the two predictors and the interaction 
5.    One value for the Type I error (alpha) level
6.    The number of replications
```
The function used for the simulation is defined in the following box.

```{r function-1, eval=TRUE}
simPower.moderation <- function(samSize = c(50,100,150,200,250,300), 
                                errlevel = c(1,3,9), 
                                rholevel = c(0,.3,.5,.8),
                                bpar = c(.5, .3, .2),
                                alpha = 0.05,
                                rep = 1000) 
      {   
    numrow <- length(errlevel)*length(rholevel)*length(samSize)
    result <- as.data.frame(matrix(data=0, nrow = numrow, ncol= 8))
    colnames(result) <- c("N","e","rho", "rsq", "b1","b2","b3","power")
    result[,"e"] <- rep(sort(rep(errlevel,length(rholevel))),length(samSize))
    result[,"rho"] <- rep(rholevel,length(errlevel)*length(samSize))
    result[,"N"] <- sort(rep(samSize,length(errlevel)*length(rholevel)))
    
    # Make relative effects sum to one
    b1 <- bpar[1]/sum(bpar)
    b2 <- bpar[2]/sum(bpar)
    b3 <- bpar[3]/sum(bpar)

     for (N in samSize)
     {
       for (e in errlevel) 
         { 
         for (rho in rholevel)
           {
           sigma = matrix(c(1,rho,rho,1), nrow=2, ncol=2)
           
           out <- matrix(0,nrow=rep,ncol=5)
           
           for (i in 1:rep) 
             {
  
      a <- as.data.frame(mvrnorm(n = N, Sigma=sigma, mu=c(0,0)))
      colnames(a)  <- c("x","z")
      a$xz <- a$x*a$z

      error <-  rnorm(N,0,sqrt(e))   # the amount of error determines the ES

      a$y <- sqrt(b1)*a$x + sqrt(b2)*a$z + sqrt(b3)*a$xz + error

      res <- lm( y ~ x + z + xz, data=a) 
      res <- lm.beta(res)
      sig <- summary(res)$coefficients[4,5] < alpha
      rsq <- summary(res)$r.squared
 
      out[i,] <- c(rsq,  res$standardized.coefficients[-1], sig)
  
            }   # loop over replications
           
           result[((result$e == e) & (result$rho == rho) & result$N == N),c(4:8)] <- apply(out,2,mean)
           
          }     # loop over correlations between predictors
         }      # loop over error levels
       }        # loop over sample sizes
    
         return(result)

} # end function
```

This function stores the results of the simulation in a dataframe called `res`, which can be further processed.
Here, we will plot the relevant results for the power of the interaction effect.

 
### Simulation study 1: moderation in the one-level model
We simulate x, z and ε from a multivariate normal distribution using the R function mvrnorm(). In the appendix it is explained how the parameter values are connected with each other. The correlation between x and z has one of three values, representing no correlation (r = 0), small correlation (r = .30), moderate correlation (r = .50), and high (r = .80). The interaction term xz is constructed by multiplying x and z. The b coefficients are chosen as the square roots from respectively, 0.5, 0.3, and 0.2.
The y is then computed as the weighted linear combination of these three variables (see formula 1), the intercept is assumed to be zero. Finally, the variance of ε is taken as one of three values, representing small (1), medium (3), and large levels (9) of random error. This error term is also added to y and is chosen such that it corresponds with R squared values of respectively .50, .25, and .10.
Using the formula’s given in the appendix the effect sizes and R squares in all conditions are given in table 1. With uncorrelated predictors the table shows that the effect sizes (beta’s) of the three parameters are respectively, 0.50, 0.39, 0.32 in the small error condition, 0.35, 0.27, 0.22 in the medium error condition, and 0.22, 0.17, and 0.14 in the large error condition. For correlated predictors, see the other cells in table 1.

```{r checkPars, eval=TRUE, include=FALSE}

# DEFINE FUNCTION
# Assume x and z ~ N(0,1)
# check expected effect sizes using formulas from the appendix
# arlevel is relative effect of auto-regression or other covariate uncorrelated with other predictors
# rholevel is correlation between the predictors (x and z)
# errlevel is error level
# bpar provides the relative effects of x, z and xz

 checkPars  <- function(rholevel = c(0.0, 0.3, 0.8),
                        arlevel = c(0,0.5),
                        errlevel = c(0,1,3,9),
                        bpar = c(.5, .3, .2))
   {
   
   numrow <- length(rholevel)*length(arlevel)*length(errlevel)
   result <- as.data.frame(matrix(data=0, nrow = numrow, ncol= 8))
   colnames(result) <- c("AR","error","rho","b1","b2","b3","b4","rsq")
   result[,"error"] <- rep(sort(rep(errlevel,length(rholevel))),length(arlevel))
   result[,"rho"] <- rep(rholevel,length(errlevel)*length(arlevel))
   result[,"AR"] <- sort(rep(arlevel,length(errlevel)*length(rholevel)))
   
   for (ar in arlevel) 
   {
     # Make relative effects sum to one
     b1 <- bpar[1]/(sum(bpar) + ar)
     b2 <- bpar[2]/(sum(bpar) + ar)
     b3 <- bpar[3]/(sum(bpar) + ar)
     b4 <- ar/(sum(bpar) + ar)
     
     for (e in errlevel) 
     { 
       for (r in rholevel)
       {
    
   # variance of y     
   vary <- b1 + b2 + (1+r**2)*(b3) + 2*sqrt(b1)*sqrt(b2)*r + b4 + e       

   # standardized effect sizes
   be1 <- sqrt(b1)/sqrt(vary)
   be2 <- sqrt(b2)/sqrt(vary)
   be3 <- sqrt(b3)*(sqrt(1+r**2)/sqrt(vary))
   be4 <- sqrt(b4)/sqrt(vary)

   # R squared
   rsq <- (vary - e)/vary      
   
   result[((result$error == e) & (result$rho == r) & result$AR == ar),c(4:8)] <- c(be1,be2,be3,be4,rsq)
   
         }    # end rho level
       }      # end error level
     }        # end ar level
  
  return(result)
   
 } # end function

```

Table 1 is obtained by running the function checkPars. The function has as parameters the correlation between the predictors, the relative effects of the predictors, including the interaction term, the relative effect of an independent covariate (e.g. auto-regression), and an error level. In this simulation we will not use the additional covariate nor the auto-regression term.

```{r CheckPars2, include=TRUE, eval=TRUE}

out <- checkPars(rholevel = c(0.0, 0.3, 0.6),
                 arlevel = c(0.0),
                 errlevel = c(0,1,3,9),
                 bpar = c(.5, .3, .2))
```
  
 
   
#### Table 1. Expected parameter values under various conditions.
 ------------------------------------------------------------------

```{r table, include=TRUE, eval=TRUE, echo=FALSE}
pander(out[,-c(1,7)])
```
 ------------------------------------------------------------------
   
   
Because the relevant effect size for moderation (Beta 3) only slightly changes as the correlation changes, we report only one value of rho (r = 0.30) in subsequent analyses. The effect sizes for the interaction term seem to have a realistic and relevant range. Values smaller than 0.10 are not likely to have much practical relevance. Larger effect size values than 0.35 do not occur very often, and if they do occur it will not be problematic to detect them. Effect sizes for the interaction between 0.10 and 0.20 we call small, between 0.20 and 0.30 medium, and effect sizes above 0.30 we call large.
After generating data according to the specifications set above, we used the lm() function in R to perform the analyses. The number of replications in each condition was set 2,000.  The results are shown in Figure 1 for alpha = 0.05 and in Figure 2 for alpha = 0.01.



### Results simulation

This section reproduces the Figures used in the paper.

```{r setup2, include=FALSE}

### Show all R commands
knitr::opts_chunk$set(echo = FALSE)

### Load required packages
safeRequire('ggplot2')
safeRequire('viridis')

```

Run the function to start the simulation, according to the following function call.

```{r simulation1, eval=TRUE, echo=TRUE}

res <- simPower.moderation(samSize = c(50,100,150,200,250,300,350,400,450,500),  
                           errlevel = c(1,3,9), 
                           rholevel = c(0.3), 
                           bpar = c(.5,.3,.2),
                           alpha = 0.05, 
                           rep = 2000) 


```

Here we have chosen a type I error of alpha = 0.05. 
The results can be plotted as follows.

```{r fig1, eval=TRUE}

res$effectSize <- ordered(res$e, levels=c(1,3,9), labels= c("large","medium","small"))

fig1 <- ggplot(data=res, aes(y=power, x=N, colour=effectSize)) +
        geom_point(size=2) + geom_line(size=1) +
        geom_hline(yintercept=0.80, linetype="dashed", color = "red") +
        geom_hline(yintercept=0.90, linetype="dashed", color = "blue") +
        scale_y_continuous(breaks=seq(0.10, 1, 0.10)) + scale_x_continuous(breaks=seq(50, 500, 50) ) +
        scale_color_viridis(discrete=TRUE) +
        theme_bw(base_size = 14) +
        ggtitle("Power of interaction term, alpha=0.05") +
        theme(plot.title = element_text(size=10, hjust=0)) 
print(fig1);

### Store to disk
ggsave(plot = fig1, filename="fig1.pdf",width=7,height=5)

```

From these analyses we can conclude that with relatively large effects (> 0.30) for the interaction term a sample of N = 50 is sufficient if you accept a type I error of 5%. For N = 100 the power is even more than 90%. When the interaction corresponds with a small effect size, which is far more common, N = 350 is necessary for a power of about 80%. For alpha = 0.01 we rerun the simulation. 

```{r fig2, eval=TRUE }
res <- simPower.moderation(samSize = c(50,100,150,200,250,300,350,400,450,500),  
                           errlevel = c(1,3,9), 
                           rholevel = c(0.3), 
                           bpar = c(.5,.3,.2),
                           alpha = 0.01, 
                           rep = 2000) 

res$effectSize <- ordered(res$e, levels=c(1,3,9), labels= c("large","medium","small"))

fig2 <- ggplot(data=res, aes(y=power, x=N, colour=effectSize)) +
        geom_point(size=2) + geom_line(size=1) +
        geom_hline(yintercept=0.80, linetype="dashed", color = "red") +
        geom_hline(yintercept=0.90, linetype="dashed", color = "blue") +
        scale_y_continuous(breaks=seq(0.10, 1, 0.10)) + scale_x_continuous(breaks=seq(50, 500, 50) ) +
        scale_color_viridis(discrete=TRUE) +
        theme_bw(base_size = 14) +
        ggtitle("Power of interaction term, alpha=0.01") +
        theme(plot.title = element_text(size=10, hjust=0)) 

print(fig2);

### Store to disk
ggsave(plot = fig2,filename="fig2.pdf",width=7,height=5)

```

From these analyses we can conclude that with relatively large effects (> 0.30) for the interaction term a sample of N = 100 if you are accept a type I error of 1%. For N = 100 the power is even more than 90%. When the interaction corresponds with a small effect size, N > 500 is necessary for a power of 80%.

### Attrition and missing values 
After computing an estimate for the sample size, this estimate will almost invariable underestimate the sample size required for the study, unless you carefully address the following issues. First, participants often drop out of studies, a phenomenon called attrition in longitudinal studies. Longer and more intensive studies are likely to have higher attrition rates. Participants may also have more missing data than in cross-sectional studies, because of the intensive character of the study. Second, participants may exhibit more variation (i.e. be more different) than expected, which directly inflates the error variance and therefore the effective sample size. Third, participants sometimes provide data that is not useable (e.g. errors or unrealistic values), in which case they have to be excluded for some or all analyses. In fact, mistakes can be made at all levels during the data gathering process, which causes loss of data. Because this influences the actual required sample size, it is important to be aware of these issues. If no other guidelines are available, adding 20% to the raw estimate seems reasonable.

# Appendix

Effect sizes
One of the crucial parameters in computing power analyses is the expected effect size. We assume that x, z, and ε are normally distributed and standardized with mean 0 and variance equal to 1. The effects sizes of the three effects are the standardized coefficients (beta), defined as:

$$β_1=b_1  σ_{x}/σ_{y}  ; β_2=b_2  σ_z/σ_y   ; β_3=b_3  σ_xz/σ_y   .	$$

If x, z and xz are uncorrelated, the variance of y is:

$$ σ_y^2=b_1^2 σ_{x}^2+ b_2^2 σ_z^2+ b_3^2 σ_{xz}^2+ σ_ϵ^2=  b_1^2+ b_2^2+ b_3^2+ σ_ϵ^2  ,	[2]$$

because the variance of xz is:

$$σ_{xz}^2=σ_x^2 σ_z^2=1.$$

We choose b1, b2 and b3 such that their squares sum to 1. For example: 
b1 = sqrt(.5), b2 = sqrt(.3) and b3 = sqrt(.2). If the variance of ε is also 1, it follows that the σ_y^2 = 1 + σ_ϵ^2 = 2.  The expected R squared of this model is 0.5, which is computed by:
$$R^2=(σ_y^2- σ_e^2)/(σ_y^2 ) .	[3]$$

The three effects sizes in this example then become:

$$β_1=√.5/√2=0.500;  β_2=√.3/√2=0.387;  β_3=√.2/√2=0.316.$$

By changing the variance of the error the effect sizes can be manipulated. 

### Correlated predictors
When x and z are correlated the variance of the interaction term xz becomes:

$$σ_{xz}^2=σ_x^2 σ_z^2+cov(x^2,z^2 )- (cov(x,z))^2=1+2r^2- r^2= 1+r^2.	[4]$$

Here r is the correlation between x and z. Assuming the interaction term is independent from x and z, the variance of y then becomes:

$$σ_y^2=b_1^2 σ_x^2+ b_2^2 σ_z^2+ b_3^2 σ_{xz}^2+2b_1 b_{2}rσ_x σ_z+σ_ϵ^2=
b_1^2+ b_2^2+(1+r^2)b_3^2+2b_1 b_2 r+ σ_ϵ^2.	[5]$$

The effect sizes of x and z are computed with this variance term. For instance for x:

$$β_1=b_1  σ_x/σ_y =b_1/√(b_1^2+ b_2^2+(1+r^2)b_3^2+2b_1 b_2 r+ σ_ϵ^2 )$$

The effect size of the interaction term becomes:

$$β_3=b_3  σ_{xz}/σ_y =b_3  √(1+r^2)/√(b_1^2+ b_2^2+(1+r^2)b_3^2+2b_1 b_2 r+ σ_ϵ^2 )$$

The $R^2$ of the model with correlated predictors can be obtained as before by [3].
Using these expressions we can construct expected effected sizes in a simulation study.


# Literature

Hayes, A. (2013). Introduction to mediation, moderation, and conditional process analysis. New York, NY: Guilford. http://doi.org/978-1-60918-230-4.







